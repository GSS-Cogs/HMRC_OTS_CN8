{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_HEADERS = [\n",
    "    'observation',\n",
    "    'data_marking',\n",
    "    'statistical_unit_eng',\n",
    "    'statistical_unit_cym',\n",
    "    'measure_type_eng',\n",
    "    'measure_type_cym',\n",
    "    'observation_type',\n",
    "    'empty',\n",
    "    'obs_type_value',\n",
    "    'unit_multiplier',\n",
    "    'unit_of_measure_eng',\n",
    "    'unit_of_measure_cym',\n",
    "    'confidentuality',\n",
    "    'empty1',\n",
    "    'geographic_area',\n",
    "    'empty2',\n",
    "    'empty3',\n",
    "    'time_dim_item_id',\n",
    "    'time_dim_item_label_eng',\n",
    "    'time_dim_item_label_cym',\n",
    "    'time_type',\n",
    "    'empty4',\n",
    "    'statistical_population_id',\n",
    "    'statistical_population_label_eng',\n",
    "    'statistical_population_label_cym',\n",
    "    'cdid',\n",
    "    'cdiddescrip',\n",
    "    'empty5',\n",
    "    'empty6',\n",
    "    'empty7',\n",
    "    'empty8',\n",
    "    'empty9',\n",
    "    'empty10',\n",
    "    'empty11',\n",
    "    'empty12'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_TOPIC = [\n",
    "    'dim_id_',\n",
    "    'dimension_label_eng_',\n",
    "    'dimension_label_cym_',\n",
    "    'dim_item_id_',\n",
    "    'dimension_item_label_eng_',\n",
    "    'dimension_item_label_cym_',\n",
    "    'is_total_',\n",
    "    'is_sub_total_',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source CSV files are in Google Drive. Each file has an ID that can be used to fetch the contents directly. To find the ID of a file in Google Drive, right click on the file and \"get shareable link\". This will give you something like `https://drive.google.com/open?id=11fLsnoiWzTcA1d3nSDWvyrKQEHwIf6Hz` and the ID is the bit after `id=` in the URL.\n",
    "\n",
    "We'll download each file and cache it locally. Note that if a source file is changed in Google Drive, it won't be downloaded again unless removed from the 'in' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sourceFolder = Path('in')\n",
    "sourceFolder.mkdir(exist_ok=True)\n",
    "\n",
    "sources = [\n",
    "    ('CN8_Non-EU_cod_2012.csv', '1P7YyFF6qXKXWVtR0Vt3kkvFPOjThMQH8'),\n",
    "    ('CN8_Non-EU_cod_2013.csv', '1de-Le9ungrbdoGyvWI_RwmEhNpTmR-70'),\n",
    "    ('CN8_Non-EU_cod_2014.csv', '1oC3jlItfsUshd54KOR7yn9NxpR83iCbC'),\n",
    "    ('CN8_Non-EU_cod_2015.csv', '1H54-FYrCFa1DylCBg38RAPAeCtkGq4la'),\n",
    "    ('CN8_Non-EU_cod_2016.csv', '11fLsnoiWzTcA1d3nSDWvyrKQEHwIf6Hz')\n",
    "]\n",
    "\n",
    "for filename, google_id in sources:\n",
    "    sourceFile = sourceFolder / filename\n",
    "\n",
    "    if not (sourceFile.exists() and sourceFile.is_file()):\n",
    "        response = requests.get(f'https://drive.google.com/uc?export=download&id={google_id}')\n",
    "        with open(sourceFile, 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read each of these CSV files into a Pandas DataFrame in turn and transform into WDA style output in the 'out' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationFolder = Path('out')\n",
    "destinationFolder.mkdir(exist_ok=True)\n",
    "\n",
    "for filename, google_id in sources:\n",
    "    oldDF = pd.read_csv(sourceFolder / filename)\n",
    "    newDF = pd.DataFrame()\n",
    "    \n",
    "    newDF[\"observation\"] = oldDF[\"svalue\"]\n",
    "    \n",
    "    for col in CONST_HEADERS[1:]:\n",
    "        newDF[col] = \"\"\n",
    "    \n",
    "    newDF['time_dim_item_id'] = oldDF[\"year\"]\n",
    "    newDF['time_dim_item_label_eng'] = oldDF[\"year\"]\n",
    "    newDF['time_type'] = \"year\"\n",
    "    \n",
    "    for counter, dimension in enumerate([\"flow\", \"comcode\", \"country\"], 1):\n",
    "        for col in CONST_TOPIC:\n",
    "            newDF[col + str(counter)] = \"\"\n",
    "\n",
    "        newDF['dim_id_' + str(counter)] = dimension\n",
    "        newDF['dimension_label_eng_' + str(counter)] = dimension\n",
    "\n",
    "        newDF['dim_item_id_' + str(counter)] = oldDF[dimension]\n",
    "        newDF['dimension_item_label_eng_' + str(counter)] = oldDF[dimension]\n",
    "        \n",
    "    newDF.to_csv(destinationFolder / filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
